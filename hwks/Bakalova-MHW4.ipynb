{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071d82b7",
   "metadata": {},
   "source": [
    "## Downloading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5c44e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "from torchvision.models import VGG16_Weights\n",
    "\n",
    "model = vgg16(weights=VGG16_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b717f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138357544 elements; 138357544 non-zero elements\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def calc_weights(model):\n",
    "    result = 0\n",
    "    for p in model.features:\n",
    "        if hasattr(p, \"weight\"):\n",
    "            result += p.weight.numel()\n",
    "            result += p.bias.numel()\n",
    "    for p in model.classifier:\n",
    "        if hasattr(p, \"weight\"):\n",
    "            result += p.weight.numel()\n",
    "            result += p.bias.numel()\n",
    "    return result\n",
    "def calc_nonzero_weights(model):\n",
    "    result = 0\n",
    "    for p in model.features:\n",
    "        if hasattr(p, \"weight\"):\n",
    "            result += torch.sum(p.weight != 0.)\n",
    "            result += torch.sum(p.bias != 0.)\n",
    "    for p in model.classifier:\n",
    "        if hasattr(p, \"weight\"):\n",
    "            result += torch.sum(p.weight != 0.)\n",
    "            result += torch.sum(p.bias != 0.)\n",
    "    return result\n",
    "\n",
    "print(calc_weights(model), \"elements;\", calc_nonzero_weights(model).item(), \"non-zero elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bf9f7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import max as torch_max\n",
    "\n",
    "dataset = ImageFolder(\"ImageNet-Mini/images\", transform=VGG16_Weights.DEFAULT.transforms())\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "def evaluate(model):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in dataloader:\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch_max(output, 1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    return float(correct) / (len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1101112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6790721386693856\n",
      "CPU times: user 23min 17s, sys: 1.29 s, total: 23min 18s\n",
      "Wall time: 24min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"accuracy:\", evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0606f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553438751 bytes\n"
     ]
    }
   ],
   "source": [
    "from torch import save\n",
    "import os\n",
    "\n",
    "def get_size_on_disk(model):\n",
    "    torch.save(model.state_dict(), \"file\")\n",
    "    sz = os.path.getsize(\"file\")\n",
    "    os.remove(\"file\")\n",
    "    return sz\n",
    "\n",
    "print(get_size_on_disk(model), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49561434",
   "metadata": {},
   "source": [
    "## Неструктурированный прунинг для полносвязных и сверточных слоев\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5a4baebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "\n",
    "class PrunedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(PrunedModel, self).__init__()\n",
    "        self.model = deepcopy(model)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def prune(self, rate):\n",
    "        # Используем l1_unstructured вместо нашего подхода\n",
    "        # unstructured говорит о том, что нет ограничений на удаляемые веса\n",
    "        # l1 говорит о том, что нужно смотреть на модуль веса\n",
    "        for i, p in enumerate(self.model.features):\n",
    "            if isinstance(p, nn.Linear) or isinstance(p, nn.Conv2d):\n",
    "                self.model.features[i] = prune.l1_unstructured(p, 'weight', amount=rate)\n",
    "        for i, p in enumerate(self.model.classifier):\n",
    "            if isinstance(p, nn.Linear) or isinstance(p, nn.Conv2d):\n",
    "                self.model.classifier[i] = prune.l1_unstructured(p, 'weight', amount=rate)\n",
    "        \n",
    "p_model = PrunedModel(model)\n",
    "p_model.prune(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dfc7a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138357544 elements; 69185480 non-zero elements\n"
     ]
    }
   ],
   "source": [
    "print(calc_weights(p_model.model), \"elements;\", calc_nonzero_weights(p_model.model).item(), \"non-zero elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "adcb0f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5962273770073923\n",
      "CPU times: user 28min 49s, sys: 9min 41s, total: 38min 31s\n",
      "Wall time: 39min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"accuracy:\", evaluate(p_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "35489ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1106819839 bytes\n"
     ]
    }
   ],
   "source": [
    "print(get_size_on_disk(p_model), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e2191",
   "metadata": {},
   "source": [
    "It works! We have twice less non-zero parameters, and significantly less accuracy (it is expected because we do quite aggressive pruning). However, the computation time also doubled, and the number of bytes on disk too. This is because we also store the mask, not only the weights. Let us remove the mask and compute the metrics again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4dab4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.prune import remove\n",
    "def remove_reparametrisation(model):\n",
    "    for i, p in enumerate(model.model.features):\n",
    "        if isinstance(p, nn.Linear) or isinstance(p, nn.Conv2d):\n",
    "            model.model.features[i] = remove(p, 'weight')\n",
    "    for i, p in enumerate(model.model.classifier):\n",
    "        if isinstance(p, nn.Linear) or isinstance(p, nn.Conv2d):\n",
    "            model.model.classifier[i] = remove(p, 'weight')\n",
    "            \n",
    "remove_reparametrisation(p_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7a53d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138357544 elements; 69185480 non-zero elements\n"
     ]
    }
   ],
   "source": [
    "print(calc_weights(p_model.model), \"elements;\", calc_nonzero_weights(p_model.model).item(), \"non-zero elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9ae7820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5926586795819526\n",
      "CPU times: user 23min 18s, sys: 727 ms, total: 23min 19s\n",
      "Wall time: 23min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"accuracy:\", evaluate(p_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "68a1c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553439263 bytes\n"
     ]
    }
   ],
   "source": [
    "print(get_size_on_disk(p_model), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a771233",
   "metadata": {},
   "source": [
    "Супер! Теперь время и место на диске не увеличились, идем дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a0c37",
   "metadata": {},
   "source": [
    "## Динамическая квантизация для полносвязных слоев\n",
    "\n",
    "(Сверточные не квантизуются из коробки, в чате разрешили не квантизовать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f0ef6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq_model = torch.quantization.quantize_dynamic(\n",
    "    p_model, {nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b71c3865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123642856 elements; 61826024 non-zero elements\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def q_calc_weights(model):\n",
    "    result = 0\n",
    "    for module in model.children():\n",
    "        if type(module) == torch.ao.nn.quantized.dynamic.modules.linear.Linear:\n",
    "            result += module.weight().numel() + module.bias().numel()\n",
    "        else:\n",
    "            result += q_calc_weights(module)\n",
    "    return result\n",
    "def q_calc_nonzero_weights(model):\n",
    "    result = 0\n",
    "    for module in model.children():\n",
    "        if type(module) == torch.ao.nn.quantized.dynamic.modules.linear.Linear:\n",
    "            result += torch.sum(module.weight() != 0.) + torch.sum(module.bias() != 0.)\n",
    "        else:\n",
    "            result += q_calc_nonzero_weights(module)\n",
    "    return result\n",
    "\n",
    "print(q_calc_weights(pq_model), \"elements;\", q_calc_nonzero_weights(pq_model).item(), \"non-zero elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d01fcbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6311496303849095\n",
      "CPU times: user 22min 8s, sys: 596 ms, total: 22min 9s\n",
      "Wall time: 22min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"accuracy:\", evaluate(pq_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "964332cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182540539 bytes\n"
     ]
    }
   ],
   "source": [
    "print(get_size_on_disk(pq_model), \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027bf53",
   "metadata": {},
   "source": [
    "Вроде все тоже работает - остались нули от прунинга, размер на диске уменьшился где-то на 30% (мы квантизовали только линейные слои, так что это нормально), accuracy после прунинга подросло, а время немного понизилось"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
