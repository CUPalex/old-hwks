{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    import os\n",
    "\n",
    "    # Undo the recent upgrade of importlib-metadata\n",
    "    ## Thanks to @Mxhiu: https://stackoverflow.com/a/73932581/14473118\n",
    "    os.system(\"pip install -q importlib-metadata==4.13.0\")\n",
    "    os.system('apt-get install -y xvfb')\n",
    "    os.system('wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/xvfb -O ../xvfb')\n",
    "    # Download `atari_wrappers.py` script from github\n",
    "    os.system(\"wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week06_policy_based/atari_wrappers.py\")\n",
    "    # Download `env_batch.py` script from github    \n",
    "    os.system(\"wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week06_policy_based/env_batch.py\")\n",
    "    # Download `runners.py` script from github    \n",
    "    os.system(\"wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week06_policy_based/runners.py\")\n",
    "    \n",
    "    os.system('apt-get install -y python-opengl ffmpeg')\n",
    "    os.system('pip install pyglet==1.2.4')\n",
    "    # Update the gym environment to be compatible with the atari environment.\n",
    "    os.system('pip install gym[atari,accept-rom-license]==0.21.0')\n",
    "    os.system('python -m pip install -U pygame --user')\n",
    "\n",
    "    print('setup complete')\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: atari-py==0.2.5 in ./rl/lib/python3.8/site-packages (0.2.5)\n",
      "Requirement already satisfied: six in ./rl/lib/python3.8/site-packages (from atari-py==0.2.5) (1.16.0)\n",
      "Requirement already satisfied: numpy in ./rl/lib/python3.8/site-packages (from atari-py==0.2.5) (1.24.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting gym==0.17\n",
      "  Downloading gym-0.17.0.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in ./rl/lib/python3.8/site-packages (from gym==0.17) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./rl/lib/python3.8/site-packages (from gym==0.17) (1.24.2)\n",
      "Requirement already satisfied: six in ./rl/lib/python3.8/site-packages (from gym==0.17) (1.16.0)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting cloudpickle~=1.3.0\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: future in ./rl/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17) (0.18.3)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.17.0-py3-none-any.whl size=1648682 sha256=98e3a4681b54d8aa08359fb2cee1ce8698e77f0c1a94363f5ebeb7357551bafd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dffn85s9/wheels/28/ef/86/66dd7efd208ab3d8078fd4917870e5fded87dec762123fcaaa\n",
      "Successfully built gym\n",
      "Installing collected packages: cloudpickle, pyglet, gym\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.2.2\n",
      "    Uninstalling cloudpickle-1.2.2:\n",
      "      Successfully uninstalled cloudpickle-1.2.2\n",
      "  Attempting uninstall: pyglet\n",
      "    Found existing installation: pyglet 1.3.2\n",
      "    Uninstalling pyglet-1.3.2:\n",
      "      Successfully uninstalled pyglet-1.3.2\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.15.3\n",
      "    Uninstalling gym-0.15.3:\n",
      "      Successfully uninstalled gym-0.15.3\n",
      "Successfully installed cloudpickle-1.3.0 gym-0.17.0 pyglet-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install atari-py==0.2.5\n",
    "!pip install gym==0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting gym[atari]==0.17\n",
      "  Downloading gym-0.17.0.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting numpy>=1.10.4\n",
      "  Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting six\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle~=1.3.0\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting atari_py~=0.2.0\n",
      "  Downloading atari_py-0.2.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.17.0-py3-none-any.whl size=1648682 sha256=21cce458264413cb18a1b83f47e53ad0e73f0a7e5699052c069402d877f8be5c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6xigr_yx/wheels/28/ef/86/66dd7efd208ab3d8078fd4917870e5fded87dec762123fcaaa\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=185fa08c30cacd6f85b62d8c7c00f62eb1dbaae02e412b922848652ab5152141\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6xigr_yx/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
      "Successfully built gym future\n",
      "Installing collected packages: cloudpickle, six, Pillow, numpy, future, scipy, pyglet, opencv-python, atari_py, gym\n",
      "Successfully installed Pillow-9.4.0 atari_py-0.2.9 cloudpickle-1.3.0 future-0.18.3 gym-0.17.0 numpy-1.24.2 opencv-python-4.7.0.72 pyglet-1.5.0 scipy-1.10.1 six-1.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gym[atari]==0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying yars_revenge.bin from Roms/ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/yars_revenge.bin\n",
      "copying skiing.bin from Roms/ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/skiing.bin\n",
      "copying star_gunner.bin from Roms/ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/star_gunner.bin\n",
      "copying chopper_command.bin from Roms/ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/chopper_command.bin\n",
      "copying koolaid.bin from Roms/ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/koolaid.bin\n",
      "copying surround.bin from Roms/ROMS/Surround - Chase (Blockade) (1977) (Atari, Alan Miller - Sears) (CX2641 - 99807, 49-75105) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/surround.bin\n",
      "copying bank_heist.bin from Roms/ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/bank_heist.bin\n",
      "copying phoenix.bin from Roms/ROMS/Phoenix (1983) (Atari - GCC, Michael Feinstein, Patricia Goodson, John Mracek) (CX2673) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/phoenix.bin\n",
      "copying breakout.bin from Roms/ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/breakout.bin\n",
      "copying keystone_kapers.bin from Roms/ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/keystone_kapers.bin\n",
      "copying centipede.bin from Roms/ROMS/Centipede (1983) (Atari - GCC, Patricia Goodson, Josh Littlefield, Douglas B. Macrae) (CX2676) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/centipede.bin\n",
      "copying riverraid.bin from Roms/ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/riverraid.bin\n",
      "copying asterix.bin from Roms/ROMS/Asterix (AKA Taz) (1984) (Atari, Jerome Domurat, Steve Woita) (CX2696).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/asterix.bin\n",
      "copying krull.bin from Roms/ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/krull.bin\n",
      "copying donkey_kong.bin from Roms/ROMS/Donkey Kong (1987) (Atari) (CX26143).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/donkey_kong.bin\n",
      "copying kangaroo.bin from Roms/ROMS/Kangaroo (1983) (Atari - GCC, Patricia Goodson, Josh Littlefield, Kevin Osborn) (CX2689) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/kangaroo.bin\n",
      "copying time_pilot.bin from Roms/ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/time_pilot.bin\n",
      "copying gravitar.bin from Roms/ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/gravitar.bin\n",
      "copying tutankham.bin from Roms/ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/tutankham.bin\n",
      "copying adventure.bin from Roms/ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/adventure.bin\n",
      "copying name_this_game.bin from Roms/ROMS/Name This Game (Guardians of Treasure, Octopussy) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/name_this_game.bin\n",
      "copying king_kong.bin from Roms/ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/king_kong.bin\n",
      "copying pong.bin from Roms/ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/pong.bin\n",
      "copying freeway.bin from Roms/ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/freeway.bin\n",
      "copying video_pinball.bin from Roms/ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/video_pinball.bin\n",
      "copying battle_zone.bin from Roms/ROMS/Battlezone (1983) (Atari - GCC, Michael Feinstein, Patricia Goodson, Brad Rice) (CX2681) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/battle_zone.bin\n",
      "copying defender.bin from Roms/ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/defender.bin\n",
      "copying frogger.bin from Roms/ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/frogger.bin\n",
      "copying crazy_climber.bin from Roms/ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/crazy_climber.bin\n",
      "copying up_n_down.bin from Roms/ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/up_n_down.bin\n",
      "copying berzerk.bin from Roms/ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/berzerk.bin\n",
      "copying pitfall.bin from Roms/ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/pitfall.bin\n",
      "copying montezuma_revenge.bin from Roms/ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
      "copying qbert.bin from Roms/ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/qbert.bin\n",
      "copying mr_do.bin from Roms/ROMS/Mr. Do! (1983) (CBS Electronics - Individeo, Ed English) (4L4478) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/mr_do.bin\n",
      "copying trondead.bin from Roms/ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/trondead.bin\n",
      "copying ms_pacman.bin from Roms/ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark S. Ackerman, Patricia Goodson, Josh Littlefield, Douglas B. Macrae, Glenn Parker) (CX2675) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/ms_pacman.bin\n",
      "copying jamesbond.bin from Roms/ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Dan Kurczewski, Louis Marbel, Kathy Von) (PB5110) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/jamesbond.bin\n",
      "copying pooyan.bin from Roms/ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/pooyan.bin\n",
      "copying private_eye.bin from Roms/ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/private_eye.bin\n",
      "copying assault.bin from Roms/ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/assault.bin\n",
      "copying venture.bin from Roms/ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/venture.bin\n",
      "copying enduro.bin from Roms/ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/enduro.bin\n",
      "copying demon_attack.bin from Roms/ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/demon_attack.bin\n",
      "copying galaxian.bin from Roms/ROMS/Galaxian (1983) (Atari - GCC, Mark S. Ackerman, Tom Calderwood, Patricia Goodson, Glenn Parker) (CX2684) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/galaxian.bin\n",
      "copying double_dunk.bin from Roms/ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/double_dunk.bin\n",
      "copying gopher.bin from Roms/ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/gopher.bin\n",
      "copying hero.bin from Roms/ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/hero.bin\n",
      "copying laser_gates.bin from Roms/ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/laser_gates.bin\n",
      "copying carnival.bin from Roms/ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/carnival.bin\n",
      "copying amidar.bin from Roms/ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/amidar.bin\n",
      "copying atlantis.bin from Roms/ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/atlantis.bin\n",
      "copying zaxxon.bin from Roms/ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/zaxxon.bin\n",
      "copying sir_lancelot.bin from Roms/ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/sir_lancelot.bin\n",
      "copying elevator_action.bin from Roms/ROMS/Elevator Action (1983) (Atari, Dan Hitchens, Dave Staugas) (CX26126) (Prototype) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/elevator_action.bin\n",
      "copying alien.bin from Roms/ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/alien.bin\n",
      "copying space_invaders.bin from Roms/ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/space_invaders.bin\n",
      "copying boxing.bin from Roms/ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/boxing.bin\n",
      "copying lost_luggage.bin from Roms/ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/lost_luggage.bin\n",
      "copying air_raid.bin from Roms/ROMS/Air Raid (1982) (Men-A-Vision) (PAL) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/air_raid.bin\n",
      "copying kaboom.bin from Roms/ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, CAG-010, AG-010-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/kaboom.bin\r\n",
      "copying beam_rider.bin from Roms/ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/beam_rider.bin\r\n",
      "copying asteroids.bin from Roms/ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/asteroids.bin\r\n",
      "copying road_runner.bin from patched version of Roms/ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/road_runner.bin\r\n",
      "copying kung_fu_master.bin from Roms/ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/kung_fu_master.bin\r\n",
      "copying tennis.bin from Roms/ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/tennis.bin\r\n",
      "copying bowling.bin from Roms/ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/bowling.bin\r\n",
      "copying pacman.bin from Roms/ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/pacman.bin\r\n",
      "copying ice_hockey.bin from Roms/ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/ice_hockey.bin\r\n",
      "copying wizard_of_wor.bin from Roms/ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/wizard_of_wor.bin\r\n",
      "copying journey_escape.bin from Roms/ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/journey_escape.bin\r\n",
      "copying seaquest.bin from Roms/ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/seaquest.bin\r\n",
      "copying solaris.bin from Roms/ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/solaris.bin\r\n",
      "copying fishing_derby.bin from Roms/ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/fishing_derby.bin\r\n",
      "copying robotank.bin from Roms/ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/robotank.bin\r\n",
      "copying frostbite.bin from Roms/ROMS/Frostbite (Iceman) (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /home/alkobakalova/rl/rl/lib/python3.8/site-packages/atari_py/atari_roms/frostbite.bin\r\n"
     ]
    }
   ],
   "source": [
    "! python3 -m atari_py.import_roms Roms/ROMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Advantage-Actor Critic (A2C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will implement Advantage Actor Critic algorithm that trains on a batch of Atari 2600 environments running in parallel.\n",
    "\n",
    "Firstly, we will use environment wrappers implemented in file `atari_wrappers.py`. These wrappers preprocess observations (resize, grayscale, take max between frames, skip frames and stack them together) and rewards. Some of the wrappers help to reset the environment and pass `done` flag equal to `True` when agent dies.\n",
    "File `env_batch.py` includes implementation of `ParallelEnvBatch` class that allows to run multiple environments in parallel. To create an environment we can use `nature_dqn_env` function. Note that if you are using\n",
    "PyTorch and not using `tensorboardX` you will need to implement a wrapper that will log **raw** total rewards that the *unwrapped* environment returns and redefine the implemention of `nature_dqn_env` function here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Process Process-2:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "Process Process-3:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "Process Process-4:\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-5:\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "Traceback (most recent call last):\n",
      "Process Process-7:\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "Process Process-8:\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/home/alkobakalova/rl/env_batch.py\", line 123, in worker\n",
      "    env = make_env_function()\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 332, in <lambda>\n",
      "    lambda i=i, env_seed=env_seed: nature_dqn_env(\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "  File \"/home/alkobakalova/rl/atari_wrappers.py\", line 343, in nature_dqn_env\n",
      "    env = gym.make(env_id)\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 142, in make\n",
      "    return registry.make(id, **kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 87, in make\n",
      "    env = spec.make(**kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/registration.py\", line 59, in make\n",
      "    env = cls(**_kwargs)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/gym/envs/atari/atari_env.py\", line 49, in __init__\n",
      "    self.game_path = atari_py.get_game_path(game)\n",
      "  File \"/home/alkobakalova/.local/lib/python3.8/site-packages/atari_py/games.py\", line 20, in get_game_path\n",
      "    raise Exception('ROM is missing for %s, see https://github.com/openai/atari-py#roms for instructions' % (game_name,))\n",
      "Exception: ROM is missing for space_invaders, see https://github.com/openai/atari-py#roms for instructions\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a552fc767247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnature_dqn_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SpaceInvadersNoFrameskip-v4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnenvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rl/atari_wrappers.py\u001b[0m in \u001b[0;36mnature_dqn_env\u001b[0;34m(env_id, nenvs, seed, summaries, clip_reward)\u001b[0m\n\u001b[1;32m    329\u001b[0m                              f\"length equal to nenvs which is {nenvs}\")\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         env = ParallelEnvBatch([\n\u001b[0m\u001b[1;32m    332\u001b[0m             lambda i=i, env_seed=env_seed: nature_dqn_env(\n\u001b[1;32m    333\u001b[0m                 env_id, seed=env_seed, summaries=False, clip_reward=False)\n",
      "\u001b[0;32m~/rl/env_batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, make_env, nenvs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mobservation_spaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_spaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_connections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mob_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mobservation_spaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0maction_spaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got end of file during message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from atari_wrappers import nature_dqn_env, NumpySummaries\n",
    "\n",
    "\n",
    "env = nature_dqn_env(\"SpaceInvadersNoFrameskip-v4\", nenvs=8, summaries='Numpy')\n",
    "obs = env.reset()\n",
    "assert obs.shape == (8, 84, 84, 4)\n",
    "assert obs.dtype == np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to implement a model that predicts logits and values. It is suggested that you use the same model as in [Nature DQN paper](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf) with a modification that instead of having a single output layer, it will have two output layers taking as input the output of the last hidden layer. **Note** that this model is different from the model you used in homework where you implemented DQN. You can use your favorite deep learning framework here. We suggest that you use orthogonal initialization with parameter $\\sqrt{2}$ for kernels and initialize biases with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as torch\n",
    "# import torch as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "agent = nn.Sequential(\n",
    "    nn.Conv2d(4, 32, (8, 8), stride=4),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, (4, 4), stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, (3, 3), stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3136, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, n_actions + 1),\n",
    ")\n",
    "\n",
    "for p in agent:\n",
    "    if hasattr(p, \"weight\"):\n",
    "        nn.init.orthogonal_(p.weight, gain=np.sqrt(2))\n",
    "    if hasattr(p, \"bias\"):\n",
    "        nn.init.zeros_(p.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to define and use a policy that wraps the model. While the model computes logits for all actions, the policy will sample actions and also compute their log probabilities.  `policy.act` should return a dictionary of all the arrays that are needed to interact with an environment and train the model.\n",
    " Note that actions must be an `np.ndarray` while the other\n",
    "tensors need to have the type determined by your deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def act(self, inputs):\n",
    "        # <Implement policy by calling model, sampling actions and computing their log probs>\n",
    "        # Should return a dict containing keys ['actions', 'logits', 'log_probs', 'values'].\n",
    "        inputs = torch.tensor(inputs / 255).permute(0, 3, 1, 2)\n",
    "        output = self.model(inputs)\n",
    "        logits = output[:, :-1]\n",
    "        values = output[:, -1].flatten()\n",
    "        return {\n",
    "            \"actions\": np.random.choice(n_actions, p=F.softmax(logits)),\n",
    "            \"logits\": logits,\n",
    "            \"log_probs\": F.log_softmax(logits, dim=-1),\n",
    "            \"values\": values\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next will pass the environment and policy to a runner that collects partial trajectories from the environment.\n",
    "The class that does is is already implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runners import EnvRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runner interacts with the environment for a given number of steps and returns a dictionary containing\n",
    "keys\n",
    "\n",
    "* 'observations'\n",
    "* 'rewards'\n",
    "* 'resets'\n",
    "* 'actions'\n",
    "* all other keys that you defined in `Policy`\n",
    "\n",
    "under each of these keys there is a python `list` of interactions with the environment. This list has length $T$ that is size of partial trajectory. Partial trajectory for given moment `t` is part of `ComputeValueTargets.__call__` input argument `trajectory` from moment `t` to the end (i.e. it's different at each iteration in the algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the part of the model that predicts state values you will need to compute the value targets.\n",
    "Any callable could be passed to `EnvRunner` to be applied to each partial trajectory after it is collected.\n",
    "Thus, we can implement and use `ComputeValueTargets` callable.\n",
    "The formula for the value targets is simple:\n",
    "\n",
    "$$\n",
    "\\hat v(s_t) = \\left( \\sum_{t'=0}^{T - 1} \\gamma^{t'}r_{t+t'} \\right) + \\gamma^T \\hat{v}(s_{t+T}),\n",
    "$$\n",
    "\n",
    "In implementation, however, do not forget to use\n",
    "`trajectory['resets']` flags to check if you need to add the value targets at the next step when\n",
    "computing value targets for the current step. You can access `trajectory['state']['latest_observation']`\n",
    "to get last observations in partial trajectory &mdash; $s_{t+T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeValueTargets:\n",
    "    def __init__(self, policy, gamma=0.99):\n",
    "        self.policy = policy\n",
    "\n",
    "    def __call__(self, trajectory):\n",
    "        # This method should modify trajectory inplace by adding\n",
    "        # an item with key 'value_targets' to it.\n",
    "        <Compute value targets for a given partial trajectory>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing value targets we will transform lists of interactions into tensors\n",
    "with the first dimension `batch_size` which is equal to `env_steps * nenvs`, i.e. you essentially need\n",
    "to flatten the first two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeTimeBatch:\n",
    "    \"\"\" Merges first two axes typically representing time and env batch. \"\"\"\n",
    "    def __call__(self, trajectory):\n",
    "        # Modify trajectory inplace.\n",
    "        <TODO: implement>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = <Create your model here>\n",
    "policy = Policy(model)\n",
    "runner = EnvRunner(\n",
    "    env, policy, nsteps=5,\n",
    "    transforms=[\n",
    "        ComputeValueTargets(),\n",
    "        MergeTimeBatch(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the time to implement the advantage actor critic algorithm itself. You can look into your lecture,\n",
    "[Mnih et al. 2016](https://arxiv.org/abs/1602.01783) paper, and [lecture](https://www.youtube.com/watch?v=Tol_jw5hWnI&list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37&index=20) by Sergey Levine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2C:\n",
    "    def __init__(self,\n",
    "                 policy,\n",
    "                 optimizer,\n",
    "                 value_loss_coef=0.25,\n",
    "                 entropy_coef=0.01,\n",
    "                 max_grad_norm=0.5):\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.value_loss_coef = value_loss_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "\n",
    "    def policy_loss(self, trajectory):\n",
    "        # You will need to compute advantages here.\n",
    "        <TODO: implement>\n",
    "\n",
    "    def value_loss(self, trajectory):\n",
    "        <TODO: implement>\n",
    "\n",
    "    def loss(self, trajectory):\n",
    "        <TODO: implement>\n",
    "\n",
    "    def step(self, trajectory):\n",
    "        <TODO: implement>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train your model. With reasonable hyperparameters training on a single GTX1080 for 10 million steps across all batched environments (which translates to about 5 hours of wall clock time)\n",
    "it should be possible to achieve *average raw reward over last 100 episodes* (the average is taken over 100 last\n",
    "episodes in each environment in the batch) of about 600. You should plot this quantity with respect to\n",
    "`runner.step_var` &mdash; the number of interactions with all environments. It is highly\n",
    "encouraged to also provide plots of the following quantities (these are useful for debugging as well):\n",
    "\n",
    "* [Coefficient of Determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) between\n",
    "value targets and value predictions\n",
    "* Entropy of the policy $\\pi$\n",
    "* Value loss\n",
    "* Policy loss\n",
    "* Value targets\n",
    "* Value predictions\n",
    "* Gradient norm\n",
    "* Advantages\n",
    "* A2C loss\n",
    "\n",
    "For optimization we suggest you use RMSProp with learning rate starting from 7e-4 and linearly decayed to 0, smoothing constant (alpha in PyTorch and decay in TensorFlow) equal to 0.99 and epsilon equal to 1e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c = <Create instance of the algorithm>\n",
    "\n",
    "<Write your training loop>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target networks?\n",
    "\n",
    "You may recall a technique called \"target networks\" we used a few weeks ago when we trained a DQN agent to play Atari Breakout and wonder why we have not suggested using them here. The answer is that this is more historical than practical.\n",
    "\n",
    "While the \"chasing the target\" problem is still present in actor-critic value estimation and target networks do show up in follow-up papers, the original A3C/A2C papers do not mention them and do not explain this omission.\n",
    "\n",
    "The hypothesis why this may not be a big deal (compared to Q-learning) goes like this. An A3C/A2C agent selects actions based on policy, not an epsilon greedy exploration function, for which the argmax can change drastically due to tiny errors in function approximation. Therefore, errors in the value target caused by target chasing will cause less damage.\n",
    "\n",
    "Also, the actor-critic gradient relies on the advantage function $A(s_t, a_t) = Q(s_t, a_t) - V(s_t)$. Compare this to the $Q$-function $Q(s_t, a_t) = r(s_t, a_t) + \\gamma \\cdot \\mathbb{E}_{s_{t+1} \\mid s_t, a_t} V(s_{t+1})$ used in Q-learning and SARSA: we would expect that any bias in $V$-function approximation will be carried over from $V(s_{t+1})$ to $V(s_t)$ by gradient updates. However, in the formula for the advantage function the two approximations ($Q$-function and $V$-function) come with opposite signs, and thus the errors will cancel out.\n",
    "\n",
    "The last reason may be computational. Authors were concerned to beat existent algorithms in the wall-clock learning time, and any overhead of parameter copying (target network update) counted against this goal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
